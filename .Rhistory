str(df.both)
df.both[ sort(df.both$gdprank, na.last = TRUE, decreasing = TRUE),]
df.both[ order(df.both$gdprank, na.last = TRUE, decreasing = TRUE),]
df.both[13,]
dfb <- df.both[ order(df.both$gdprank, na.last = TRUE, decreasing = TRUE),]
dfb[13,]
dim(df.both)
str(dfcountry)
dfcountry2 <- dfcountry[ , 1:3]
#df.all <- merge(dfgdp2, dfcountry2,  all = TRUE)
#dim(df.all)
df.both <- merge(dfgdp2, dfcountry2,  all = FALSE)
dim(df.both)
str(df.both)
dfb <- df.both[ order(df.both$gdprank, na.last = TRUE, decreasing = TRUE),]
dfb[13,]
dim(df.both)
describe(df.both$Income.Group)
?table
?tapply
tapply(df.both$gdprank, df.both$Income.Group, mean)
tapply(df.both$gdprank, df.both$Income.Group, mean, na.rm= TRUE)
?cut
cut(df.both$gdprank, breaks=5)
df.both$gdpcut <- cut(df.both$gdprank, breaks=quantile(df.both$gdprank))
table(df.both$gdpcut)
table(df.both$gdprank, df.both$gdpcut)
?table
head(df.both, n=20)
tail(df.both)
38*5
df.both[ df.both$Income.Group == "Lower middle income" & gdprank <= 38, ]
df.both[ df.both$Income.Group == "Lower middle income" & df.both$gdprank <= 38, ]
ls()
rm(ls())
?rm
rm(list=ls())
?merge
version()
install.packages("stringi")
install.packages(c("CORElearn", "hybridEnsemble", "markdown", "pkgmaker", "psych", "repmis", "VSURF"))
install.packages("MXM")
install.packages("gRbase")
install.packages("imputeR")
install.packages(c("bigrf", "hybridEnsemble", "multicore", "roxygen2", "R.utils", "stringi"))
install.packages("FLR")
library(manipulate)
myPlot <- function(s) {
plot(cars$dist - mean(cars$dist), cars$speed - mean(cars$speed))
abline(0, s)
}
manipulate(myPlot(s), s = slider(0,2, step=0.01))
require(rCharts)
haireye = as.data.frame(HairEyeColor)
n1 <- nPlot(Freq ~ Hair, group = 'Eye', type = 'multiBarChart',
data = subset(haireye, Sex == 'Male')
)
n1$save('fig/n1.html', cdn = TRUE)
cat('<iframe src="fig/n1.html" width=100%, height=600></iframe>')
require(devtools)
install_github('rCharts', 'ramnathv')
require(rCharts)
?rCharts
?dTable
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
ad <- AlzheimerDisease
str(predictors)
colnames(predictors)
x <- c(1,0,1,0)
y <- c(1,2,3,4)
data.frame(x,y)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
library(ggplot2)
qplot(mixtures$CompressiveStrength, inTrain)
str(inTrain)
str(mixtures$CompressiveStrength)
str(mixtures$CompressiveStrength) +geom()
?qplot
qplot(training$CompressiveStrength, inTrain)
qplot(y=training$CompressiveStrength, x=inTrain)
require(Hmisc)
qplot(y=training$CompressiveStrength, x=inTrain, color=cut2(training$Cement, g=3))
qplot(y=training$CompressiveStrength, x=inTrain, color=cut2(training$Cement, g=5))
qplot(y=training$CompressiveStrength, x=inTrain, color=cut2(training$Cement, g=4))
qplot(y=training$CompressiveStrength, x=inTrain, color=cut2(training$Cement, g=3))
qplot(y=training$CompressiveStrength, x=inTrain, color=cut2(training$FlyAsh, g=3))
hist(training$Superplasticizer)
hist(training$Superplasticizer, breaks=20)
summary(training)
summary(log10(training$Superplasticizer))
sp <- training$Superplasticizer
boxplot(sp)
pairs(training)
?skewness
?skew
??skew
require(e1071)
skewness(sp)
preObj <- preProcess(training, method=c("BoxCox"))
trainSP <- predict(preObj, training)$Superplasicizer
hist(trainSP)
str(trainSP)
trainSP <- predict(preObj, training)$Superplasticizer
hist(trainSP)
str(trainSP)
summary(trainSP)
dev.off()
hist(trainSP)
hist(sp)
par(mfrow=c(1,1))
hist(trainSP)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
str(training)
SP <- training$Superplasticizer
str(SP)
summary(SP)
?preProcess
scaledSP <- preProcess(SP)
length(SP)
SP <- matrix(c(1,774), 1,774)
head(SP)
dim(SP)
SP <- training$Superplasticizer
head(SP)
tail(SP)
scaledSP <- preProcess(SP)
boxcoxSP <- preProcess(training$Superplasticizer, method=c("BoxCox"))
boxcoxSP <- preProcess(training, method=c("BoxCox"))
dim(boxcoxSP)
str(boxcoxSP)
log(0)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
prePRoc <- preProcess( training[,-c("diagnosis")], method="pca", pcaComp=9)
colnames(training)
prePRoc <- preProcess( training[,-1], method="pca", pcaComp=9)
str(training)
sapply(training, class)
head(training$Genotype)
prePRoc <- preProcess( training[,-c(1, -1], method="pca", pcaComp=9)
prePRoc <- preProcess( training[,-c(1, 131)], method="pca", pcaComp=9)
str(preProc)
str(prePRoc)
trainPC <- predict(prePRoc, training[,-c(1, 131)])
modelFit <- train(training$diagnosis ~ ., method="glm", data=trainPC)
modelFit
prePRoc
prePRoc <- preProcess( training[,-c(1, -1], method="pca")
prePRoc <- preProcess( training[,-c(1, -1)], method="pca")
prePRoc <- preProcess( training[,-c(1, -1)], method=c(BoxCox","center","scaled","pca")
prePRoc <- preProcess( training[,-c(1, -1)], method=c("BoxCox","center","scaled","pca")
)
prePRoc <- preProcess( training[,-c(1, -1)], method=c("BoxCox","center","scaled","pca") )
prePRoc <- preProcess( training[,-c(1, -1)], method="pca")
prePRoc <- preProcess( training[,-c(1, -1)], method=c("pca"))
prePRoc <- preProcess( training[,-c(1, 131)], method="pca", pcaComp=9)
?preProcess
prePRoc <- preProcess( training[,-c(1, 131)], method="pca", thresh=0.9)
prePRoc
colnames(training)
cn<-colnames(training)
grep("^IL", cn)
cn[grep("~IL", cn)]
cn[grep("^IL", cn)]
myCol <- cn[grep("^IL", cn)]
prePRoc <- preProcess( training[,myCol], method="pca", thresh=0.9)
prePRoc
training <- training[,myCol]
training <- cbind(training, diagonsis)
dim(diagnosis)
length(diagnosis)
dim(training)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
myTrain <- cbind(training[ intrain, myCol], diagnosis[intrain])
myTrain <- cbind(training[ inTrain, myCol], diagnosis[inTrain])
dim(myTrain)
head(myTrain)
tail(myTrain)
asisModel <- train(diagnosis ~., data=myTrain, method="glm")
library(devtools)
install_github('slidify','ramnathv')
install_github('slidifyLibraries','ramnathv')
library(slidify)
install.packages(c("Boruta", "C50", "caret", "Cubist", "ezsim", "gamboostLSS", "gss", "klaR", "maptools", "matrixStats", "MCMCglmm", "R.cache", "Rcpp", "RcppArmadillo", "ReporteRs", "rjson", "Rmalschains", "tau", "TDMR", "yaml"))
install.packages(c("Boruta", "C50", "caret", "Cubist", "ezsim",
install.packages(c("Boruta", "C50", "caret", "Cubist", "ezsim", "gamboostLSS", "gss", "klaR", "maptools", "matrixStats", "MCMCglmm", "R.cache", "Rcpp", "RcppArmadillo", "ReporteRs", "rjson", "Rmalschains", "tau", "TDMR", "yaml"))
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
set.seed(125)
inTrain <- createDataPartition( y=segmentationOriginal$Case, p=0.5, list=FALSE)
trainingset <- segmentationOriginal[inTrain,]
testingset <- segmentationOriginal[-inTrain]
trainingset <- segmentationOriginal[inTrain,]
testingset <- segmentationOriginal[-inTrain]
head(traininset)
head(trainingset)
summary(segmentationOriginal$Case)
segmentationOriginal[ 1:10, 1:10]
trainingset <- segmentationOriginal[ segmentationOriginal$Case == 'train', 3:ncol(segmentationOriginal) ]
dim(trainingset)
trainingset <- segmentationOriginal[ segmentationOriginal$Case == 'Train', 3:ncol(segmentationOriginal) ]
dim(trainingset)
testingset <- segmentationOriginal[ segmentationOriginal$Case == 'Test', 3:ncol(segmentationOriginal) ]
modelFit <- train(Class ~., data=segmentationOriginal, method="glm")
)
modelFit <- train(Class ~., data=segmentationOriginal, method="rpart")
print(modelFit$finalModel)
set.seed(125)
modelFit <- train(Class ~., data=segmentationOriginal, method="rpart")
print(modelFit$finalModel)
library(rattle)
fancyRpartPlot(modelFit$finalModel)
plot(modelFit$finalModel, uniform=TRUE, main="myTree")
predict(modelFit, newdata=testingset)
str(modelFit)
colnames(segmentationOriginal)
trainingset <- segmentationOriginal[ segmentationOriginal$Case == 'Train', -2 ]
dim(trainingset)
testingset <- segmentationOriginal[ segmentationOriginal$Case == 'Test', -2 ]
dim(testingset)
set.seed(125)
modelFit <- train(Class ~., data=segmentationOriginal, method="rpart")
print(modelFit$finalModel)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
trainingset <- segmentationOriginal[ segmentationOriginal$Case == 'Train', -2 ]
dim(trainingset)
testingset <- segmentationOriginal[ segmentationOriginal$Case == 'Test', -2 ]
dim(testingset)
set.seed(125)
modelFit <- train(Class ~., data=segmentationOriginal, method="rpart")
print(modelFit$finalModel)
plot(modelFit$finalModel, uniform=TRUE, main="myTree")
text(modelFit$finalModel, use.n = TRUE, all=TRUE, cex=.8)
library(rattle)
fancyRpartPlot(modelFit$finalModel)
library(pgmm)
data(olive)
olive = olive[,-1]
newdata = as.data.frame(t(colMeans(olive)))
newdata
inTrain <- createDataPartition( y=olive$Area, p=0.7, list=FALSE)
inTrain
trainingset <- olive[ inTrain, ]
dim(trainingset)
testingset <- olive[ -inTrain, ]
dim(testingset)
modelFit <- train(Area ~., data=olive, method="tree")
require(tree)
?tree
modelFit <- tree(Area ~., data=olive)
summary(modelFit)
modelFit
plot(modelFit); text(modelFit)
plot(modelFit$finalModel, uniform=TRUE, main="myTree")
plot(modelFit); text(modelFit)
predict(modelFit, newdata=newdata)
summary(olive$Area)
table(olive%Area)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
datasets(ElemStatLearn)
data(SAheart)
set.seed(13234)
modelFit <- train(chd ~., data=trainSA, method="glm", family="binomial")
print(modelFit$finalModel)
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
?predict
?caret
predicted <- predict(trainSA$chd, modelFit)
trainpredicted <- predict(modelFit, newdata=trainSA)
trainpredicted
missClass( trainSA$chd, trainpredicted )
testpredicted <- predict(modelFit, newdata=testSA)
missClass( testSA$chd, testpredicted )
includedcolumns <- c("age","alcolhol","obesity","tobacco","typea","ldl", "chd")
set.seed(13234)
modelFit <- train(chd ~., data=trainSA[,includedcolumns], method="glm", family="binomial")
trainSA <- trainSA[ ,includedcolumns]
includedcolumns <- c("age","alcohol","obesity","tobacco","typea","ldl", "chd")
trainSA <- trainSA[ ,includedcolumns]
testSA <- testSA[ , includedcolumns]
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
# my code
set.seed(13234)
modelFit <- train(chd ~., data=trainSA[,includedcolumns], method="glm", family="binomial")
print(modelFit$finalModel)
trainpredicted <- predict(modelFit, newdata=trainSA)
missClass( trainSA$chd, trainpredicted )
testpredicted <- predict(modelFit, newdata=testSA)
missClass( testSA$chd, testpredicted )
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
dim(vowel.train)
str(vowel.train)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
modelFit <- train(y ~., data=vowel.train, method="rf")
print(modelFit$finalModel)
?varImp
varImp(modelFit)
setwd("~/Documents/online-learning/data-science-practical-machine-learning-2014/code")
testing <- read.csv("pml-testing.csv")
training <- read.csv("pml-training.csv", na.strings=c("","NA"))
dim(training)
dim(testing)
# take a closer look at the data
# str(training)
# require(Hmisc)
# describe(training)
# let's try getting rid of the summary statistics columns first
# determine which columns have a lot of NA's'
idx<-apply(training, 2, function(x) sum(is.na(x)))
# describe(idx)
# RESULTS: this shows that there were 60 columns that had values for every observation,
# and 100 columns with 19216 NA's in that column
# so create a column index of which columns to keep
keepthesecolumns <- ifelse(idx == 0, TRUE, FALSE)
# new training set without the columns of summary statistics
training2 <- training[,keepthesecolumns]
testing2 <- testing[, keepthesecolumns]
dim(training2)
dim(testing2)
str(training2)
#str(testing2)
# now get rid of the first 7 fields - since these were descriptive as well
training3 <- training2[,8:ncol(training2)]
testing3 <- testing2[,8:ncol(testing2)]
dim(training3)
dim(testing3)
# now turn the class variable 'classe' into a factor
training3$classe <- factor(as.character( training3$classe) )
# since randomforest takes a long time,
# let's train against smaller subsets for testing purposes
TEST = TRUE # FALSE
if(TEST) {
index <- sample(nrow(training),size=500, replace= FALSE )
training3 <- training3[ index, ]
dim(training3)
}
# Split into a training set, and a testing set,
# and save the 20 obs as a validation set
library(caret)
# create trainSet, testSet, validationSet
inTrain <- createDataPartition( y=training3$classe, p=0.7,  list=FALSE)
trainSet <- training3[inTrain, ]
testSet <- training3[-inTrain, ]
validationSet <- testing3
dim(trainSet)
dim(testSet)
dim(validationSet)
set.seed(12345)
# use out-of-bag sampling instead of cross-validation to find the
# best choice of paramters, ie. mtry
ctrl <- trainControl(method="oob", number=5)
modelFit <- train(classe~., data=trainSet, method="rf",
trControl=ctrl, ntree=500, tuneLength=5, metric="Accuracy")
modelFit
pred <- predict(modelFit, trainSet)
print("Model accuracy based on training set")
table(pred, trainSet$classe)
pred <- predict(modelFit, testSet)
print("Model accuracy based on held out testing set")
table(pred, testSet$classe)
# Report on the variables with the most importance
varImp(modelFit)
varlist <- varImp(modelFit)
# plot those variables with the  most importance
vli <- varlist$importance[ order(varlist$importance$Overall, decreasing=TRUE), ,drop=FALSE]
numShown <- 10
myBars <- as.matrix(vli[1:numShown,])
myNames <- rownames(vli)[1:numShown]
op <- par(no.readonly = TRUE) # the whole list of settable par's.
par(mai=c(1,2,1,1)+0.1 ) # expand left margin)
barplot(myBars,
horiz=TRUE,
beside = TRUE,
names.arg = myNames,
cex.names=0.7,
las=1,  # asix labels always horizontal
xlab="Relative Importance",
main=paste0("Top ", as.character(numShown), " Variables ranked by Importance"))
par(op)
testpred <- predict(modelFit, testing3)
print("Predictions made on validation set")
testpred
# write out the files for submission
answers <- as.character(testpred)
# submission
# answers = rep("A", 20) ie as a character vector
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
# this will write out twenty separate files, one for each answer
# into your working directory
pml_write_files(answers)
setwd("~/Documents/online-learning/data-science-practical-machine-learning-2014/code")
testing <- read.csv("pml-testing.csv")
training <- read.csv("pml-training.csv", na.strings=c("","NA"))
# convert all character colummns to numeric, except classe
dim(training)
dim(testing)
str(training)
require(Hmisc)
describe(training)
#
idx<-apply(training, 2, function(x) sum(is.na(x)))
describe(idx)
keepthesecolumns <- ifelse(idx == 0, TRUE, FALSE)
# new training set without the columns of summary statistics
training2 <- training[,keepthesecolumns]
testing2 <- testing[, keepthesecolumns]
dim(training2)
keepthesecolumns <- ifelse(idx == 0, TRUE, FALSE)
# new training set without the columns of summary statistics
training2 <- training[,keepthesecolumns]
testing2 <- testing[, keepthesecolumns]
dim(training2)
dim(testing2)
str(training2)
str(testing2)
# now get rid of the first 7 fields
training3 <- training2[,8:ncol(training2)]
testing3 <- testing2[,8:ncol(testing2)]
dim(training3)
dim(testing3)
# now turn the class variable 'classe' into a factor
training3$classe <- factor(as.character( training3$classe) )
TEST = TRUE
if(TEST) {
index <- sample(nrow(training),size=500, replace= FALSE )
training3 <- training3[ index, ]
dim(training3)
}
library(caret)
# create trainSet, testSet, validationSet
inTrain <- createDataPartition( y=training3$classe, p=0.7,  list=FALSE)
trainSet <- training3[inTrain, ]
testSet <- training3[-inTrain, ]
validationSet <- testing3
dim(trainSet)
dim(testSet)
dim(validationSet)
# from Applied Predictive Modeling, page 436
set.seed(12345)
ctrl <- trainControl(method="oob", number=5)
modelFit <- train(classe~., data=trainSet, method="rf",
trControl=ctrl, ntree=500, tuneLength=5, metric="Accuracy")
modelFit
#getTree(modelFit$finalModel, k=2)
pred <- predict(modelFit, trainSet)
print("Model accuracy based on training set")
table(pred, trainSet$classe)
pred <- predict(modelFit, testSet)
print("Model accuracy based on held out testing set")
table(pred, testSet$classe)
?confustionMatrix
?confusionMatrix
confusionMatrix(data= pred,  # predicted results
reference= testSet$classe  )                    # true results
cm<-confusionMatrix(data= pred,  # predicted results
reference= testSet$classe  )                    # true results
str(cm)
cm$Overall$Accuracy
cm$overall$Accuracy
cm$overall
str(cm$overall)
cm$overall$Accuracy
cm$overall["Accuracy"]
cm
myAccuracy <-cm$overall$Accuracy
myAccuracy <- cm$overall["Accuracy"]
myAccuracy
round(myAccuracy, 3)
as.character(round(myAccuracy, 3))
?knitr
